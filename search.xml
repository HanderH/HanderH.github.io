<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Exception]]></title>
    <url>%2F2019%2F06%2F29%2Fexception%2F</url>
    <content type="text"><![CDATA[java中的异常分为哪几类看图： 在java中，所有异常都都有一个共同的祖先Throwable,Throwable有两个重要的子类，Exception和error error:是程序无法处理的错误，表示程序有严重的错误，大多数错误都是jvm出现的问题，如StackOverError,OutOfMemoryError. Exception:程序本身可以处理的异常。它有一个子类RuntimeException,这一类异常有java虚拟机抛出，如NullException(要访问的变量没有引用任何对象)，ArithmeticException(算术异常，整数除以０时)，ArrayIndexOutOfBoundsException(下标越界) 异常处理 try:用于捕获异常，后面可以接多个catch,如果后面没有catch,则必须接finally catch:用于处理try捕获的异常 finally:无论是否捕获或者处理异常，finally块中的语句都会被执行，当tyr或catch块中遇到return语句时，finally语句块将在方法返回之前执行 throw和throws的区别 throw 用在方法体中，表示抛出异常，由方法体内的语句处理 throw是抛出异常的一个动作，抛出的是一个异常实例，执行throw一定抛出了某种异常 throws 用在方法声明后面，表示如果抛出异常，由该方法的调用者处理 throws主要是用来声明这个方法可能会抛出某种异常，让它的使用者知道需要捕获的异常类型 final,finally,finalize的区别 final :用来声明属性，方法和类，表示属性不可变，方法不可覆盖，类不可继承 finally:异常处理语句结构的一部分，表示总是执行 finalize:Object的一个方法，在垃圾回收器执行的时候会调用被回收对象的此方法，当该方法被调用则代表该对象即将死亡。当我们主动去调用该方法并不会导致该对象的死亡，这是一个回调方法，不需要我们调用]]></content>
  </entry>
  <entry>
    <title><![CDATA[equals]]></title>
    <url>%2F2019%2F06%2F29%2Fequals%2F</url>
    <content type="text"><![CDATA[equals()方法与==的区别 ==:对于基本类型比较的是值，对于引用类型比较的是地址 123456789101112public static void main(String[] args) &#123; int a = 10; int b = 10; System.out.println(a == b);//true String str1 = &quot;hello&quot;; String str2 = &quot;hello&quot;; System.out.println(str1 == str2);//true String str3 = new String(&quot;hello&quot;); String str4 = new String(&quot;hello&quot;); System.out.println(str3 == str4);//false &#125; 在这里解释一下String类型在jvm是怎样存储的 如果使用“”创建String类型，如str1,str2,它会去常量池查找有没有当前我要创建的值，如果有直接将常量池的引用复制给该变量。第一次使用String str1 = “hello”，由于常量池中没有“hello”，它会在常量池中创建，在使用String str2 = “hello”，由于常量池中存在”hello”，str2它会直接引用这个值，所以str1 == str2为true 使用new创建String对象的时候，它回到常量池去查找有没有我要创建的值，如果有则拷贝一份到堆中，将该副本的引用赋值给变量。如果没有，则实例化该对象放到常量池，并且拷贝副本到堆中，将副本的引用复制给变量 如：String str3 = new String(“hello”)，常量池创建，拷贝一份到堆中，并副本赋值给str3,String str4 = new String(“hello”)，从常量池拷贝一份到堆中，并将副本引用赋值给str4.所有str3 == str4为false equals:Object中的方法，在Object中比较的也是两个对象的地址,但是一般情况下，都要重写equals方法，来指定相等的规则。比如String类，重写equsls方法，比较的是String的值，而不是地址。 案例：一个Student类，重写equals方法，如果它的name相等就认为他们是同一个学生。 1234567891011121314151617181920212223242526272829303132public class Student &#123; private String name; private int age; public Student(String name, int age) &#123; this.name = name; this.age = age; &#125; @Override public boolean equals(Object obj) &#123; //两个对象的地址相等，一定是同一个对象 if(this==obj) &#123; return true; &#125; if(obj instanceof Student) &#123; Student s = (Student) obj; if(this.name.equals(s.name)) &#123; return true; &#125; &#125; return false; &#125; public static void main(String[] args) &#123; Student s1 = new Student(&quot;zs&quot;, 18); Student s2 = new Student(&quot;zs&quot;, 20); System.out.println(s1.equals(s2));//true System.out.println(s1 == s2);//false &#125;&#125; eausle的特性 自反性：a.equals(a)一定为true 对称性: 如果a.equals(b)为true，那么b.equals(a)一定也为true 传递性: a.equals(b)为true,b.equals(c)为true,那么a.equals(c)也为true equals与hashcode重写equals是否需要重写hashcode? 在api中是建议在重写equals时，我们有必要重写hashcode. 在一些用到hashcode的数据结构存储数据的时候，如hashset,是一定要重写的hashcode的 hashset存放元素的时候存放的是不重复的元素，它存数据的时候会根据元素的hash值和equals方法来判断是否添加，如果两个元素的hash值相同和equals方法返回为true,则认为元素相同，hashset不将它添加进去。这样就会产生一个问题，假设有 student1 = new Student(“zs”,18),student2 = new Student(“zs”,18),hashset在添加这两个对象的时候，只会将一个对象添加进去，但是如果不重写hashcode,hastset会认为这是两个不同的元素并将它添加进去，当我们在从hashset中取出数据的时候会发现取出了两个相同对象，这与hashset的的规则不符合，所以重写equals方需要重写hashcode. hashset添加元素的判断 12if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) 案例：一个Student类，重写equals,不重写hashcode,创建两个属性相等的对象，存放到hashset 1234567891011121314@Override public boolean equals(Object obj) &#123; //两个对象的地址相等，一定是同一个对象 if(this==obj) &#123; return true; &#125; if(obj instanceof Student) &#123; Student s = (Student) obj; if(this.name.equals(s.name)&amp;&amp;this.age == s.age) &#123; return true; &#125; &#125; return false; &#125; 存放到hashset,并输出到控制台 1234567891011121314public static void main(String[] args) &#123; Student s1 = new Student(&quot;zs&quot;, 18); Student s2 = new Student(&quot;zs&quot;, 18); HashSet&lt;Student&gt; set = new HashSet&lt;&gt;(); set.add(s1); set.add(s2); Iterator&lt;Student&gt; iterator = set.iterator(); while(iterator.hasNext()) &#123; Student next = iterator.next(); System.out.println(next); &#125;&#125; 输出结果]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[clone() 浅拷贝与深拷贝]]></title>
    <url>%2F2019%2F06%2F29%2Fclone-%E6%B5%85%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B7%B1%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[clone的用法用来复制一个对象的副本，产生一个新的对象，新对象的属性与原对象的属性一致，而且原对象的改变不影响新对象 克隆有浅拷贝与深拷贝，用的时候一定要注意 使用对象的clone()方法时，需要实现Cloneable接口,这是一个标志接口，不提供任何抽象方法 12public interface Cloneable &#123;&#125; 浅拷贝先来看一段代码： 123456789101112131415161718192021222324public class Persion implements Cloneable&#123; private int age; private String name; public Persion(int age, String name) &#123; this.age = age; this.name = name; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; public static void main(String[] args) throws CloneNotSupportedException &#123; Persion p = new Persion(18,&quot;zｈang&quot;); Persion p2 = (Persion) p.clone(); System.out.println(p.name == p2.name); &#125;&#125; 它的打印结果是什么呢？ true 没看错，就是这个结果，有没有困惑的地方？这就是由于浅拷贝导致的。看张图： 由于name是String类型，拷贝的只是它的引用,所以他们的name的地址值是相等的 那怎样将它改为深拷贝呢？ 如果是引用类型，我们需要重新在原对象的基础上重新创建出一个对象。 例如，将上面改为深拷贝，只需要修改一下clone方法 12345678@Override protected Object clone() throws CloneNotSupportedException &#123; String newName = new String(this.name);//拷贝原对象的name值 Persion p = (Persion)super.clone(); p.name = newName; return p; &#125; 深拷贝再来看一个深拷贝的例子： A要实现深拷贝，必须要求其属性中含有的引用类型也必须进行深拷贝，也就是要求B要进行深拷贝 123456789101112131415161718192021222324252627282930313233343536373839class A implements Cloneable&#123; int id; B b; public A(int id, B b) &#123; this.id = id; this.b = b; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; //深拷贝 B nb = (B) b.clone(); A na = (A) super.clone(); na.b = nb; return na; &#125;&#125;class B implements Cloneable &#123; String name; B(String name) &#123; this.name = name; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; B b = (B) super.clone(); String sname = new String(name); b.name = sname; return b; &#125;&#125;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flume]]></title>
    <url>%2F2019%2F06%2F27%2FFlume%2F</url>
    <content type="text"><![CDATA[一.Flume是什么Flume是一个分布式的，可靠的，高可用的海量日志采集系统，以Event为单位进行传输 二.Flume的三大组件source数据输入端的常见类型 spooling directory :文件中的数据 exec :执行linux的命令，监控文件数据 syslog:文件日志 avro:序列化框架 netcat:监听端口 channel缓冲区 位于Source和Sink,flume自带两种缓冲区Memory Channel,File Channel Memoey Channel :基于内存缓存，在不关心数据丢失的情况下使用 File Channel : 持久化Channel,不易丢失数据 sink数据输出端常见的目的地包括Hdfs,Kafka,logger,avro,file 三.Flume的操作1.监控指定端口，并采集数据，输出到控制台agent: source使用netcat,监控指定的端口 先检测要监听的端口是否已经被占用 1sudo netstat -tunlp | grep 44444 123sudo netstat -tunlp | grep 44444参数说明： -t:tcp -u:udp -n:网络连接 -l:listener p:进程 channel使用memory sink使用logger 创一个配置文件:vi netcat.flm 12345678910111213141516171819# Name the components on this agenta1.sources = r1 // a1:agent的名称 r1:source的名称a1.sinks = k1 // k1:sink的名称a1.channels = c1 //c1:channel的名称# Describe/configure the sourcea1.sources.r1.type = netcat a1.sources.r1.bind = localhost //绑定本机a1.sources.r1.port = 44444 //监听对应端口# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memory# Bind the source and sink to the channela1.sources.r1.channels = c1 // source输出到指定channela1.sinks.k1.channel = c1 //channel到指定的sink 执行命令，启动agent： 123flume-ng agent -c flume/conf/ -f netcat.flm -n a1 -Dflume.root.logger=INFO,console//-c:指定flume的配置文件 －f:指定要执行的配置文件 -n:agent的名字，要与配置中一致 使用telnet测试 1telnet local host message 2.实时采集数据并输出到控制台agent: ​ source使用exec ​ 配置文件 vi exec.flm 12345678910111213141516171819202122# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F /home/briup/log/test.log //要监控的文件# 命令从-c后的字符串读取a1.sources.r1.shell = /bin/sh -c# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 运行agent 1flume-ng agent -c flume/conf/ -f exec.flm -n a1 -Dflume.root.logger=INFO,console 3.Spool监测配置的目录下新增的文件agent: spooldir 1mkdir spool //先创建一个目录，指定这个目录为要监听的目录 配置文件：vi spool.flm 1234567891011121314a1.sources = r1a1.sinks = k1a1.channels = c1a1.sources.r1.type = spooldira1.sources.r1.spoolDir =/home/master/spoola1.sources.r1.fileHeader = truea1.sinks.k1.type = loggera1.channels.c1.type = memorya1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动agent 1flume-ng agent -c flume/conf/ -f spool.flm -n a1 -Dflume.root.logger=INFO,console 4.Syslogtcp监听TCP的端口做为数据源agent:syslogtcp vi syslogtcp.flm //配置文件 12345678910111213141516sources = r1a1.sinks = k1a1.channels = c1a1.sources.r1.type = syslogtcpa1.sources.r1.port = 5140a1.sources.r1.host = localhosta1.sinks.k1.type = loggera1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100a1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动agent 1flume-ng agent -c flume/conf/ -f syslogtcp.flm -n a1 -Dflume.root.logger=INFO,console 测试 1echo &quot;hello world&quot; | nc localhost 5140 三.agent执行原理 source接受事件 channel处理器处理事件后，被拦截器拦截 拦截器处理后，进入channel选择器，根据channel选择器的选择结果，将事件写入对应的channel Sink选择器选择其中一个Sink去获取Channel数据，并将数据写入到下一个阶段 channel选择器：1. Replicating Channel Selector:将source发过来的events发往所有channel 2. Multiplexing channel Selector:可以将事件配置发往哪些Channel五.flume的高可用1.故障转移利用备份agent，当原来的agent挂掉后，切换到备份agent,需要使用到一个前置agent，或者是一个java程序来读取原来的数据，通过sink组(processor)输出到不同的agent. 配置实现 首先配置前置的agent，vi pre_flm 123456789101112131415161718192021222324252627282930313233343536373839a1.sources = r1a1.sinks = k1 k2a1.channels = c1 c2#这个是配置failover的关键，需要有一个sink groupa1.sinkgroups = g1a1.sinkgroups.g1.sinks = k1 k2#处理的类型是failovera1.sinkgroups.g1.processor.type = failover#优先级，数字越大优先级越高，每个sink的优先级必须不相同a1.sinkgroups.g1.processor.priority.k1 = 5a1.sinkgroups.g1.processor.priority.k2 = 10#设置为10秒，当然可以根据你的实际状况更改成更快或者很慢a1.sinkgroups.g1.processor.maxpenalty = 10000 # Describe/configure the sourcea1.sources.r1.type = syslogtcpa1.sources.r1.port = 5140a1.sources.r1.channels = c1 c2a1.sources.r1.selector.type = replicating# Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.channel = c1a1.sinks.k1.hostname = localhosta1.sinks.k1.port = 5555 a1.sinks.k2.type = avroa1.sinks.k2.channel = c2a1.sinks.k2.hostname = localhosta1.sinks.k2.port = 6666 # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 a1.channels.c2.type = memorya1.channels.c2.capacity = 1000a1.channels.c2.transactionCapacity = 100 第二配置agent与back_agent vi agent.flm vi back_agent.flm 12345678910111213141516171819202122232425262728293031323334353637#agent.flma1.sources = r1a1.sinks = k1a1.channels = c1Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 6666 Describe the sinka1.sinks.k1.type = loggerUse a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1#back_agent.flma1.sources = r1a1.sinks = k1a1.channels = c1Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5555Describe the sinka1.sinks.k1.type = loggerUse a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 然后就可以使用命令启动这些配置了，先启动agent和back_agent，再启动pre_flm 然后向pre_flm发送数据，发现agent会接受到数据，使用crtl c关闭agent，会发现back_agent可以接受到数据。 12345flume-ng agent -c flume/conf/ -f pre.flm -n a1 -Dflume.root.logger=INFO,consoleflume-ng agent -c flume/conf/ -f agent.flm -n a1 -Dflume.root.logger=INFO,consoleflume-ng agent -c flume/conf/ –f agent_back.flm -n a1 -Dflume.root.logger=INFO,console 2.负载均衡利用前置的agent，通过processor向多个agent轮询的发送数据 首先配置前置的agent，vi pre_flm 12345678910111213141516171819202122232425262728293031323334353637a1.sources = r1a1.sinks = k1 k2a1.channels = c1 c2 #这个是配置Load balancing的关键，需要有一个sink groupa1.sinkgroups = g1a1.sinkgroups.g1.sinks = k1 k2a1.sinkgroups.g1.processor.type = load_balance#是否是开启退避功能a1.sinkgroups.g1.processor.backoff = true＃轮询a1.sinkgroups.g1.processor.selector = round_robin # Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5140a1.sources.r1.channels = c1 # Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.channel = c1a1.sinks.k1.hostname = localhosta1.sinks.k1.port = 5555 a1.sinks.k2.type = avroa1.sinks.k2.channel = c2a1.sinks.k2.hostname = localhosta1.sinks.k2.port = 6666 # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100a1.channels.c2.type = memory 第二配置agent a与agnet b vi a.flm vi b.flm 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#a.flma1.sources = r1a1.sinks = k1a1.channels = c1 # Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5555 # Describe the sinka1.sinks.k1.type = logger # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 # Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1#b.flma1.sources = r1a1.sinks = k1a1.channels = c1 # Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5555 # Describe the sinka1.sinks.k1.type = logger # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 # Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1]]></content>
      <tags>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java设计模式(单例模式)]]></title>
    <url>%2F2019%2F06%2F26%2Fjava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式之单例模式一.什么是单例模式​ 确保类只有一个实例，不会出现多个 二.单例模式解决了什么问题​ 保证类在内存的对象唯一 三.单例模式的两种形式饿汉式public class Single{ private static static Single instance = new Single(); private Single(){ } public static Single getInstance(){ return instance; } }１．为什么叫这种模式为饿汉式？ ​ 类在加载的时候就创建好了这个对象 ２．为什么构造方法是私有的，方法是静态的，属性也是静态的？ ​ 首先单例模式只创建一个实例，是不能通过new去创建实例的，所以构造方法是私有的 ​ 第二不能通过实例去调用方法，只能通过类名去访问，所以方法是静态的 由于静态方法只能访 问静态的属性所以属性也是静态的。 懒汉式线程不安全1234567891011121314151617public class Single｛ private static Single single = null; public Single&#123; &#125; public static Single getInstance()&#123; if(single == null)&#123; single = new Single(); &#125; return single; &#125; &#125; 线程安全1234567891011121314151617public class Single&#123; private static Single single = null; public static Single getInstance()&#123; if(single == null)&#123; //如果single已经实例化，则不在去获取锁，提高效率 synchronized(Single.class)&#123; if(single == null)&#123; single = new Single(); &#125; &#125; &#125; return single; &#125;&#125; ​]]></content>
      <tags>
        <tag>java 设计模式</tag>
      </tags>
  </entry>
</search>
