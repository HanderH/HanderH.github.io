<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flume]]></title>
    <url>%2F2019%2F06%2F27%2FFlume%2F</url>
    <content type="text"><![CDATA[一.Flume是什么Flume是一个分布式的，可靠的，高可用的海量日志采集系统，以Event为单位进行传输 二.Flume的三大组件source数据输入端的常见类型 spooling directory :文件中的数据 exec :执行linux的命令，监控文件数据 syslog:文件日志 avro:序列化框架 netcat:监听端口 channel缓冲区 位于Source和Sink,flume自带两种缓冲区Memory Channel,File Channel Memoey Channel :基于内存缓存，在不关心数据丢失的情况下使用 File Channel : 持久化Channel,不易丢失数据 sink数据输出端常见的目的地包括Hdfs,Kafka,logger,avro,file 三.Flume的操作1.监控指定端口，并采集数据，输出到控制台agent: source使用netcat,监控指定的端口 先检测要监听的端口是否已经被占用 1sudo netstat -tunlp | grep 44444 123sudo netstat -tunlp | grep 44444参数说明： -t:tcp -u:udp -n:网络连接 -l:listener p:进程 channel使用memory sink使用logger 创一个配置文件:vi netcat.flm 12345678910111213141516171819# Name the components on this agenta1.sources = r1 // a1:agent的名称 r1:source的名称a1.sinks = k1 // k1:sink的名称a1.channels = c1 //c1:channel的名称# Describe/configure the sourcea1.sources.r1.type = netcat a1.sources.r1.bind = localhost //绑定本机a1.sources.r1.port = 44444 //监听对应端口# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memory# Bind the source and sink to the channela1.sources.r1.channels = c1 // source输出到指定channela1.sinks.k1.channel = c1 //channel到指定的sink 执行命令，启动agent： 123flume-ng agent -c flume/conf/ -f netcat.flm -n a1 -Dflume.root.logger=INFO,console//-c:指定flume的配置文件 －f:指定要执行的配置文件 -n:agent的名字，要与配置中一致 使用telnet测试 1telnet local host message 2.实时采集数据并输出到控制台agent: ​ source使用exec ​ 配置文件 vi exec.flm 12345678910111213141516171819202122# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F /home/briup/log/test.log //要监控的文件# 命令从-c后的字符串读取a1.sources.r1.shell = /bin/sh -c# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 运行agent 1flume-ng agent -c flume/conf/ -f exec.flm -n a1 -Dflume.root.logger=INFO,console 3.Spool监测配置的目录下新增的文件agent: spooldir 1mkdir spool //先创建一个目录，指定这个目录为要监听的目录 配置文件：vi spool.flm 1234567891011121314a1.sources = r1a1.sinks = k1a1.channels = c1a1.sources.r1.type = spooldira1.sources.r1.spoolDir =/home/master/spoola1.sources.r1.fileHeader = truea1.sinks.k1.type = loggera1.channels.c1.type = memorya1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动agent 1flume-ng agent -c flume/conf/ -f spool.flm -n a1 -Dflume.root.logger=INFO,console 4.Syslogtcp监听TCP的端口做为数据源agent:syslogtcp vi syslogtcp.flm //配置文件 12345678910111213141516sources = r1a1.sinks = k1a1.channels = c1a1.sources.r1.type = syslogtcpa1.sources.r1.port = 5140a1.sources.r1.host = localhosta1.sinks.k1.type = loggera1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100a1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动agent 1flume-ng agent -c flume/conf/ -f syslogtcp.flm -n a1 -Dflume.root.logger=INFO,console 测试 1echo &quot;hello world&quot; | nc localhost 5140 三.agent执行原理 source接受事件 channel处理器处理事件后，被拦截器拦截 拦截器处理后，进入channel选择器，根据channel选择器的选择结果，将事件写入对应的channel Sink选择器选择其中一个Sink去获取Channel数据，并将数据写入到下一个阶段 channel选择器：1. Replicating Channel Selector:将source发过来的events发往所有channel 2. Multiplexing channel Selector:可以将事件配置发往哪些Channel五.flume的高可用1.故障转移利用备份agent，当原来的agent挂掉后，切换到备份agent,需要使用到一个前置agent，或者是一个java程序来读取原来的数据，通过sink组(processor)输出到不同的agent. 配置实现 首先配置前置的agent，vi pre_flm 123456789101112131415161718192021222324252627282930313233343536373839a1.sources = r1a1.sinks = k1 k2a1.channels = c1 c2#这个是配置failover的关键，需要有一个sink groupa1.sinkgroups = g1a1.sinkgroups.g1.sinks = k1 k2#处理的类型是failovera1.sinkgroups.g1.processor.type = failover#优先级，数字越大优先级越高，每个sink的优先级必须不相同a1.sinkgroups.g1.processor.priority.k1 = 5a1.sinkgroups.g1.processor.priority.k2 = 10#设置为10秒，当然可以根据你的实际状况更改成更快或者很慢a1.sinkgroups.g1.processor.maxpenalty = 10000 # Describe/configure the sourcea1.sources.r1.type = syslogtcpa1.sources.r1.port = 5140a1.sources.r1.channels = c1 c2a1.sources.r1.selector.type = replicating# Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.channel = c1a1.sinks.k1.hostname = localhosta1.sinks.k1.port = 5555 a1.sinks.k2.type = avroa1.sinks.k2.channel = c2a1.sinks.k2.hostname = localhosta1.sinks.k2.port = 6666 # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 a1.channels.c2.type = memorya1.channels.c2.capacity = 1000a1.channels.c2.transactionCapacity = 100 第二配置agent与back_agent vi agent.flm vi back_agent.flm 12345678910111213141516171819202122232425262728293031323334353637#agent.flma1.sources = r1a1.sinks = k1a1.channels = c1Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 6666 Describe the sinka1.sinks.k1.type = loggerUse a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1#back_agent.flma1.sources = r1a1.sinks = k1a1.channels = c1Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5555Describe the sinka1.sinks.k1.type = loggerUse a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 然后就可以使用命令启动这些配置了，先启动agent和back_agent，再启动pre_flm 然后向pre_flm发送数据，发现agent会接受到数据，使用crtl c关闭agent，会发现back_agent可以接受到数据。 12345flume-ng agent -c flume/conf/ -f pre.flm -n a1 -Dflume.root.logger=INFO,consoleflume-ng agent -c flume/conf/ -f agent.flm -n a1 -Dflume.root.logger=INFO,consoleflume-ng agent -c flume/conf/ –f agent_back.flm -n a1 -Dflume.root.logger=INFO,console 2.负载均衡利用前置的agent，通过processor向多个agent轮询的发送数据 首先配置前置的agent，vi pre_flm 12345678910111213141516171819202122232425262728293031323334353637a1.sources = r1a1.sinks = k1 k2a1.channels = c1 c2 #这个是配置Load balancing的关键，需要有一个sink groupa1.sinkgroups = g1a1.sinkgroups.g1.sinks = k1 k2a1.sinkgroups.g1.processor.type = load_balance#是否是开启退避功能a1.sinkgroups.g1.processor.backoff = true＃轮询a1.sinkgroups.g1.processor.selector = round_robin # Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5140a1.sources.r1.channels = c1 # Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.channel = c1a1.sinks.k1.hostname = localhosta1.sinks.k1.port = 5555 a1.sinks.k2.type = avroa1.sinks.k2.channel = c2a1.sinks.k2.hostname = localhosta1.sinks.k2.port = 6666 # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100a1.channels.c2.type = memory 第二配置agent a与agnet b vi a.flm vi b.flm 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#a.flma1.sources = r1a1.sinks = k1a1.channels = c1 # Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5555 # Describe the sinka1.sinks.k1.type = logger # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 # Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1#b.flma1.sources = r1a1.sinks = k1a1.channels = c1 # Describe/configure the sourcea1.sources.r1.type = avroa1.sources.r1.channels = c1a1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 5555 # Describe the sinka1.sinks.k1.type = logger # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100 # Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1]]></content>
      <tags>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java设计模式(单例模式)]]></title>
    <url>%2F2019%2F06%2F26%2Fjava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式之单例模式一.什么是单例模式​ 确保类只有一个实例，不会出现多个 二.单例模式解决了什么问题​ 保证类在内存的对象唯一 三.单例模式的两种形式饿汉式public class Single{ private static static Single instance = new Single(); private Single(){ } public static Single getInstance(){ return instance; } }１．为什么叫这种模式为饿汉式？ ​ 类在加载的时候就创建好了这个对象 ２．为什么构造方法是私有的，方法是静态的，属性也是静态的？ ​ 首先单例模式只创建一个实例，是不能通过new去创建实例的，所以构造方法是私有的 ​ 第二不能通过实例去调用方法，只能通过类名去访问，所以方法是静态的 由于静态方法只能访 问静态的属性所以属性也是静态的。 懒汉式线程不安全1234567891011121314151617public class Single｛ private static Single single = null; public Single&#123; &#125; public static Single getInstance()&#123; if(single == null)&#123; single = new Single(); &#125; return single; &#125; &#125; 线程安全1234567891011121314151617public class Single&#123; private static Single single = null; public static Single getInstance()&#123; if(single == null)&#123; //如果single已经实例化，则不在去获取锁，提高效率 synchronized(Single.class)&#123; if(single == null)&#123; single = new Single(); &#125; &#125; &#125; return single; &#125;&#125; ​]]></content>
      <tags>
        <tag>java 设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[My New Hexo]]></title>
    <url>%2F2019%2F06%2F26%2FMy-New-Post%2F</url>
    <content type="text"><![CDATA[一级标题​ 二级标题三级标题 列表一 列表二百度]]></content>
      <categories>
        <category>java</category>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>测试使用</tag>
        <tag>java</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F06%2F26%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
